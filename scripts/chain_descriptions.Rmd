---
title: "Chain descriptions"
output: pdf_document
---

```{r, setup, include=FALSE}
knitr::opts_knit$set(root.dir = "/Users/nadeaus/Repos/cov-swiss-phylogenetics")
knitr::opts_chunk$set(root.dir = "/Users/nadeaus/Repos/cov-swiss-phylogenetics")
```

```{r, include=FALSE}
require(dplyr)
require(ggplot2)
require(xtable)
source("../grapevine/database/R/utility.R")
source("../grapevine/utility_functions.R")
source("../grapevine/generate_figures/functions.R")
source("scripts/figures_shared_vars.R")
```

Load data

```{r}
workdir <- "results_main"
outdir <- paste(workdir, "output", sep = "/")
outdir <- "figures"
grapevine_results <- load_grapevine_results(
  workdir = workdir, 
  min_chain_size = 1,
  viollier_only = F)
samples <- grapevine_results$samples
```

Summarize data

```{r}
chain_summary_stats <- samples %>%
  group_by(tree, chains_assumption, chain_idx) %>%
  summarize(
    first_sample_date = min(date),
    last_sample_date = max(date),
    first_sample_month = format(first_sample_date, "%Y-%m-01"),
    last_sample_month = format(last_sample_date, "%Y-%m-01"),
    size = n(),
    .groups = "drop") %>%
  mutate(time_to_last_sample = difftime(last_sample_date, first_sample_date, units = "days"))

chain_longevity_stats <- chain_summary_stats %>%
  mutate(first_sample_month_2 = first_sample_month) %>%
  tidyr::pivot_longer(
    cols = c("first_sample_month_2", "last_sample_month"),
    names_to = "date_type",
    values_to = "date") %>%
  mutate(date = as.Date(date)) %>%
  tidyr::unite(col = "tree_chain", tree, chain_idx) %>%
  group_by(tree_chain, chains_assumption) %>%
  tidyr::complete(
    date = seq.Date(min(date), max(date), by = "month")) %>%
  tidyr::fill(first_sample_month) %>%
  group_by(chains_assumption, first_sample_month, date) %>%
  summarize(n_chains = n(), .groups = "drop") %>%
  filter(first_sample_month < "2020-12-01")
```

Write out stats for paper

```{r}
con <- file("manuscript/chain_summary_variables.tex", open = "w")

n_chains_min <- nrow(chain_summary_stats %>%
  filter(chains_assumption == "min"))
writeLines(text = paste0("\\newcommand\\nchainsmin{", n_chains_min, "}"), con = con)

n_chains_max <- nrow(chain_summary_stats %>%
  filter(chains_assumption == "max"))
writeLines(text = paste0("\\newcommand\\nchainsmax{", n_chains_max, "}"), con = con)

largest_chains_percent_min <- chain_summary_stats %>%
  ungroup() %>%
  filter(chains_assumption == "min") %>%
  arrange(desc(size)) %>%
  mutate(
    cum_size = cumsum(size),
    total_samples = sum(size),
    cum_per_total = cum_size / total_samples)
largest_chains_percent_min <- round(largest_chains_percent_min[[10, "cum_per_total"]] * 100)
writeLines(text = paste0("\\newcommand\\minlargestchainsper{", largest_chains_percent_min, "}"), con = con)

largest_chains_percent_max <- chain_summary_stats %>%
  ungroup() %>%
  filter(chains_assumption == "max") %>%
  arrange(desc(size)) %>%
  mutate(
    cum_size = cumsum(size),
    total_samples = sum(size),
    cum_per_total = cum_size / total_samples)
largest_chains_percent_max <- round(largest_chains_percent_max[[10, "cum_per_total"]] * 100)
writeLines(text = paste0("\\newcommand\\maxlargestchainsper{", largest_chains_percent_max, "}"), con = con)

tbl <- chain_longevity_stats %>%
  filter(chains_assumption == "min", 
         first_sample_month == "2020-02-01", 
         date == as.Date("2020-11-01")) %>%
  ungroup() %>%
  select(n_chains)
n_spanning_chains_min <- ifelse(test = nrow(tbl) > 0, yes = unlist(tbl), no = 0)
writeLines(text = paste0("\\newcommand\\nspanningchainsfebnovmin{", n_spanning_chains_min, "}"), con = con)

tbl <- chain_longevity_stats %>%
  filter(chains_assumption == "max", 
         first_sample_month == "2020-02-01", 
         date == as.Date("2020-11-01")) %>%
  ungroup() %>%
  select(n_chains)
n_spanning_chains_max <- ifelse(test = nrow(tbl) > 0, yes = unlist(tbl), no = 0)
writeLines(text = paste0("\\newcommand\\nspanningchainsfebnovmax{", n_spanning_chains_max, "}"), con = con)

ggplot(
  data = chain_summary_stats,
  aes(x = time_to_last_sample)) + 
  geom_histogram() + 
  facet_wrap(. ~ chains_assumption)

time_to_last_sample_summary <- chain_summary_stats %>%
  group_by(chains_assumption) %>%
  summarize(
    mean_time_to_last_sample = round(mean(time_to_last_sample)),
    median_time_to_last_sample = median(time_to_last_sample))

writeLines(text = paste0("\\newcommand\\meantimetolastsamplemax{", 
                         time_to_last_sample_summary[time_to_last_sample_summary$chains_assumption == "max", "mean_time_to_last_sample"], 
                         "}"), con = con)
writeLines(text = paste0("\\newcommand\\meantimetolastsamplemin{", 
                         time_to_last_sample_summary[time_to_last_sample_summary$chains_assumption == "min", "mean_time_to_last_sample"],
                         "}"), con = con)

close(con)
```

Plot chain sizes

```{r}
chain_sizes_to_plot <- c(as.character(1:30), ">30")
chain_size_data <- chain_summary_stats %>%
  mutate(
    size_to_plot = case_when(size <= 30 ~ as.character(size),
                             size > 30 ~ ">30"),
    size_to_plot = factor(
      x = size_to_plot,
      levels = chain_sizes_to_plot)) %>%
  group_by(chains_assumption, size_to_plot) %>%
  summarize(n_chains = n())
p1 <- ggplot(
  data = chain_size_data,
  aes(x = size_to_plot, y = n_chains)) + 
  geom_col() + 
  facet_grid(
    . ~ chains_assumption,
    labeller = labeller(chains_assumption = chain_assumption_labs),
    scales = "free_y") + 
  shared_theme + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) + 
  labs(x = "Introduction size", y = "Number of introductions") + 
  scale_x_discrete(
    limits = chain_sizes_to_plot,
    breaks = chain_sizes_to_plot[seq(1, length(chain_sizes_to_plot), by = 2)])
show(p1)
ggsave(
  plot = p1,
  file = paste(outdir, "chain_size_dist.png", sep = "/"),
  width = single_col_width,
  height = 0.5 * single_col_width,
  units = "cm"
)
```

Fit power-law distribution to chain sizes

```{r}
# Plot lineages of at least size vs. size like in Louis' paper
chain_size_dist_data <- chain_summary_stats %>%
    group_by(chains_assumption, size) %>%
    summarise(n_chains = n()) %>%
    arrange(desc(size)) %>%
    mutate(n_chains_greater_than_eq_to = cumsum(n_chains))
ggplot(
  data = chain_size_dist_data,
  aes(x = size, y = n_chains_greater_than_eq_to)) + 
  geom_point() + 
  scale_x_continuous(trans = "log") + 
  scale_y_continuous(trans = "log") + 
  facet_grid(. ~ chains_assumption) + 
  geom_vline(xintercept = 50, linetype = "dashed")

# fit power-law coefficient to compare to UK analysis
# want to fit P[X >= x] ~ X^-alpha
# from poweRlaw tutorial: 
# The Value column gives the number of times that particular word occurs. 
# We can fit a discrete power law in the usual waym_sp = displ$new(swiss_prot$Value)
library(poweRlaw)
power_law_data <- chain_summary_stats %>%
  filter(chains_assumption == "max", size <= 50) %>%
  group_by(size) %>%
  summarise(n_chains = n()) %>%
  arrange(desc(size)) %>%
  mutate(n_chains_greater_than_eq_to = cumsum(n_chains))
m_pl <- displ$new(power_law_data$n_chains_greater_than_eq_to)
m_pl$setXmin(1)
print(paste("max chains scaling parameter  estimate 1 <= x <= 50:", estimate_pars(m_pl)$pars))

power_law_data <- chain_summary_stats %>%
  filter(chains_assumption == "max", size > 50) %>%
  group_by(size) %>%
  summarise(n_chains = n()) %>%
  arrange(desc(size)) %>%
  mutate(n_chains_greater_than_eq_to = cumsum(n_chains))
if (nrow(power_law_data) > 1) {
  m_pl <- displ$new(power_law_data$n_chains_greater_than_eq_to)
  m_pl$setXmin(1)
  print(paste("max chains scaling parameter  estimate x > 50:", estimate_pars(m_pl)$pars))
} else {
  print("< 2 max chains with x > 50")
}

power_law_data <- chain_summary_stats %>%
  filter(chains_assumption == "min", size <= 50) %>%
  group_by(size) %>%
  summarise(n_chains = n()) %>%
  arrange(desc(size)) %>%
  mutate(n_chains_greater_than_eq_to = cumsum(n_chains))
m_pl <- displ$new(power_law_data$n_chains_greater_than_eq_to)
m_pl$setXmin(1)
print(paste("min chains scaling parameter  estimate 1 <= x <= 50:", estimate_pars(m_pl)$pars))

power_law_data <- chain_summary_stats %>%
  filter(chains_assumption == "min", size > 50) %>%
  group_by(size) %>%
  summarise(n_chains = n()) %>%
  arrange(desc(size)) %>%
  mutate(n_chains_greater_than_eq_to = cumsum(n_chains))
if (nrow(power_law_data) > 1) {
  m_pl <- displ$new(power_law_data$n_chains_greater_than_eq_to)
  m_pl$setXmin(1)
  print(paste("min chains scaling parameter  estimate x > 50:", estimate_pars(m_pl)$pars))
} else {
  print("< 2 min chains with x > 50")
}
```
Similar to Louis, I see a power-law decay in the CDF of chain number by chain size,
with a change in slope at ~ chain size 50. 

The scaling factors I estimate are much higher
than his though, especially for small chain sizes. So, Swiss chain 
sizes decay more sharply (fewer larger chains) than UK chains.

Plot chain longevity

```{r}
unique_ordered_months <- unique(sort(chain_summary_stats$first_sample_month))
chain_longevity_stats_tmp <- chain_longevity_stats %>% 
  mutate(first_sample_month = factor(
    x = first_sample_month,
    levels = unique_ordered_months,
    labels = format(as.Date(unique_ordered_months), "%b. %Y")))

p <- ggplot(
  data = chain_longevity_stats_tmp,
  aes(x = date, y = n_chains)) + 
  geom_area() + 
  facet_grid(
    first_sample_month ~ chains_assumption,
    labeller = labeller(chains_assumption = chain_assumption_labs),
    space = "free_y")

pretty_p <- p +
  labs(
    x = element_blank(),
    y = "Number of ongoing transmission chains\nby month of first sample") +
  scale_x_date(
    date_labels = "%b. %Y", date_breaks = "1 month") +
  shared_theme + 
  facet_nospace_theme_elements + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5))

show(pretty_p)

# ggsave(
#   plot = pretty_p,
#   file = paste(outdir, "chain_size_dist.png", sep = "/"),
#   width = single_col_width,
#   height = single_col_width,
#   units = "cm"
# )
```

Plot chain longevity differently

```{r}
chain_longevity_stats_tmp <- chain_longevity_stats %>% 
  mutate(
    first_sample_month = as.Date(first_sample_month),
    date = as.Date(date)) %>%
  tidyr::complete(first_sample_month, date) %>%
  filter(date >= first_sample_month) %>%
  tidyr::pivot_wider(names_from = chains_assumption, names_prefix = "chains_assumption_", values_from = n_chains) %>%
  mutate(
    chains_assumption_max = tidyr::replace_na(chains_assumption_max, 0),
    chains_assumption_min = tidyr::replace_na(chains_assumption_min, 0),
    mean_n_chains = (chains_assumption_min + chains_assumption_max) / 2,
    n_chains_range = paste(chains_assumption_min, chains_assumption_max, sep = "-\n"))


p <- ggplot(
  data = chain_longevity_stats_tmp,
  aes(x = date, y = first_sample_month)) + 
  geom_raster(aes(fill = case_when(mean_n_chains == 0 ~ -0.5, T ~ log10(mean_n_chains)))) + 
  geom_text(aes(label = n_chains_range), lineheight = .7, hjust = 0.5, vjust = 0.5) + 
  scale_y_date(date_breaks = "1 month", date_labels = "%b", expand = c(0,0)) + 
  scale_x_date(date_breaks = "1 month", date_labels = "%b", expand = c(0,0)) + 
  scale_fill_gradientn(colors = c("white", "red")) + 
  shared_theme + 
  theme(legend.position = "none") + 
  labs(x = "Month of ongoing sampling", y = "Month of first sampling")
show(p)

ggsave(
  plot = p,
  file = paste(outdir, "chain_longevity_matrix.png", sep = "/"),
  width = single_col_width,
  height = single_col_width,
  units = "cm"
)
```
# Set up contingency table to evaluate whether lockdowns contained transmission chains 
contingency table: is/is not lockdown vs. is/is not singleton transmission chain

```{r}
tmp <- grapevine_results$chains %>%
  mutate(
    is_singleton = case_when(size == 1 ~ "Singleton", T ~ "Transmission chain"),
    is_lockdown = case_when(
      tmrca >= as.Date("2020-03-17") & tmrca < as.Date("2020-04-27") ~ "MRCA during lockdown",
      T ~ "MRCA not during lockdown")) %>%
  group_by(chains_assumption, is_singleton, is_lockdown) %>%
  summarise(n_introductions = n(), .groups = "drop")

max_chains_contingency_table <- tmp %>%
  filter(chains_assumption == "max") %>%
  tidyr::pivot_wider(
    names_from = "is_singleton", 
    values_from = "n_introductions") %>%
  select(-chains_assumption)

min_chains_contingency_table <- tmp %>%
  filter(chains_assumption == "min") %>%
  tidyr::pivot_wider(
    names_from = "is_singleton", 
    values_from = "n_introductions") %>%
  select(-chains_assumption)
```

# Run Fischer's exact test
H0: the odds ratio of an introduction generating a transmission chain > size 1
during lockdown compared to outside of lockdown is 1
H0: whether an introduction generates a transmission chain > size 1
is independent of whether introduction occured during lockdown or not.

```{r}
print("Max chains contingency table:")
max_fisher_test <- fisher.test(x = max_chains_contingency_table %>% select(-is_lockdown))
print(max_fisher_test)

print("Min chains contingency table:")
min_fisher_test <- fisher.test(x = min_chains_contingency_table %>% select(-is_lockdown))
print(min_fisher_test)

# Format contingency tables nicely
max_chains_contingency_table_with_marginals <- max_chains_contingency_table %>%
  mutate(Total = Singleton + `Transmission chain`) %>%
  bind_rows(summarise(.,
                      across(where(is.numeric), sum),
                      across(where(is.character), ~"Total")))

min_chains_contingency_table_with_marginals <- min_chains_contingency_table %>%
  mutate(Total = Singleton + `Transmission chain`) %>%
  bind_rows(summarise(.,
                      across(where(is.numeric), sum),
                      across(where(is.character), ~"Total")))
```

Write out stats for paper

```{r}
con <- file("manuscript/chain_summary_variables.tex", open = "a")

writeLines(text = paste0("\\newcommand\\maxfisherpval{", 
                         signif(max_fisher_test$p.value, 2),
                         "}"), con = con)
writeLines(text = paste0("\\newcommand\\minfisherpval{", 
                         signif(min_fisher_test$p.value, 2),
                         "}"), con = con)

close(con)

colnames(max_chains_contingency_table_with_marginals)[1] <- "" 
x_max_chains_contingency_table_with_marginals <- xtable(
  x = max_chains_contingency_table_with_marginals,
  caption = "Contingency table for singleton introductions and transmission chains by time period.",
  label = "tab:max-chains-contingency",
  align = "lcccc")
print(
  x = x_max_chains_contingency_table_with_marginals,
  type = "latex",
  file = "figures/max_chains_contingency.tex",
  floating = F)
write.csv(
  x = max_chains_contingency_table_with_marginals, 
  file = "figures/max_chains_contingency.csv")

colnames(min_chains_contingency_table_with_marginals)[1] <- "" 
x_min_chains_contingency_table_with_marginals <- xtable(
  x = min_chains_contingency_table_with_marginals,
  caption = "Contingency table for singleton introductions and transmission chains by time period.",
  label = "tab:min-chains-contingency",
  align = "lcccc")
print(
  x = x_min_chains_contingency_table_with_marginals,
  type = "latex",
  file = "figures/min_chains_contingency.tex",
  floating = F)
write.csv(
  x = min_chains_contingency_table_with_marginals, 
  file = "figures/min_chains_contingency.csv")
```


