---
title: "Compare chains with different size context sets, different chain definitions"
author: "Sarah Nadeau"
date: "17/05/2021"
output: html_document
---

Note: I also tried running 5x and 10x size context sets, but Euler either timed out (5x) or ran out of memory (10x).

```{r, setup, include=FALSE}
date <- "2021-08-10"
knitr::opts_knit$set(root.dir = "/Users/nadeaus/Repos/cov-swiss-phylogenetics")
knitr::opts_chunk$set(root.dir = "/Users/nadeaus/Repos/cov-swiss-phylogenetics")
```

```{r, include=FALSE}
require(dplyr)
require(ggplot2)
source("../sars_cov_2/grapevine/database/R/utility.R")
source("../sars_cov_2/grapevine/utility_functions.R")
source("../sars_cov_2/grapevine/generate_figures/functions.R")
source("scripts/figures_shared_vars.R")
```

# Load data

```{r}
load_results <- function(
  prefix = paste0("results_all/", date, "_for_supplement_sim_"),
  suffix = "_rep_",
  reps = c("1", "2", "3"),
  values = c("1", "2", "3")
) {
  results <- list()
  for (value in values) {
    for (rep in reps) {
      fp <- paste(prefix, value, suffix, rep, sep = "")
      print(paste("Loading results in", fp))
      if (dir.exists(fp)) {
        res_desc <- paste(value, "x_rep", case_when(rep == "" ~ "0", T ~ rep), sep = "")
        results_temp <- load_grapevine_results(workdir = fp)
        results[[res_desc]] <- results_temp
      } else {
        warning(paste("Directory", fp, "does not exist."))
      }
    }
  }
  return(results)
}

results <- load_results()
```

# Add main analysis run

```{r}
fp <- "results_main"
print(paste("Loading results in", fp))
if (dir.exists(fp)) {
  res_desc <- "2x_repMain analysis"
  results_temp <- load_grapevine_results(workdir = fp)
  results[[res_desc]] <- results_temp
} else {
  warning(paste("Directory", fp, "does not exist."))
}
```

# Load runtime info

```{r}
prefix <- paste0(date, "_for_supplement_sim_")
run_info <- read.csv(file = "results_all/run_info.csv")
sim_context_to_replace <- paste0(date, "_for_manuscript")
relevant_run_info <- run_info %>%
  mutate(tmp = gsub(pattern = prefix, x = run_name, replacement = "")) %>%
  tidyr::separate(col = tmp, into = c("sim_context", "rep"), sep = "_rep_") %>%
  filter(metric == "CPU time") %>%
  select(value, sim_context, rep) %>%
  rename("runtime_sec" = value) %>%
  mutate(runtime_sec = as.numeric(runtime_sec),
         runtime_hr = runtime_sec / 60^2)

# Annotate main analysis
relevant_run_info[relevant_run_info$sim_context == sim_context_to_replace, "rep"] <- "Main analysis"
relevant_run_info[relevant_run_info$sim_context == sim_context_to_replace, "sim_context"] <- 2
```

# Compare number of introductions across down-sampling of Swiss sequences

```{r}
max_sampling_frac <- 0.05
subsample_fractions <- seq(from = 0.01, to = 0.04, by = 0.01)
n_reps <- 50
n_focal_sequences <- nrow(
  results$`2x_repMain analysis`$samples %>%
    filter(chains_assumption == "min"))
n_seqs_to_keep <- c(round(subsample_fractions * n_focal_sequences / max_sampling_frac), n_focal_sequences)
full_samples <- results$`2x_repMain analysis`$samples

for (i in 1:length(n_seqs_to_keep)) {
  for (j in 1:n_reps) {
    n_seqs <- n_seqs_to_keep[i]
    subsample <- full_samples %>% group_by(chains_assumption) %>% sample_n(size = n_seqs, replace = F)
    size_dist <- subsample %>% 
      group_by(chains_assumption, chain_idx) %>%
      summarize(size = n(), .groups = "drop")
    subsample_results_tmp <- size_dist %>%
      group_by(chains_assumption) %>%
      summarize(n_singletons = sum(size == 1),
                n_chains = sum(size > 1),
                .groups = "drop") %>%
      mutate(subsample = subsample_fractions[i],
             n_focal_seqs = n_seqs,
             rep = j)
    if (i == 1) {
      subsample_results <- subsample_results_tmp
    } else {
      subsample_results <- rbind(subsample_results, subsample_results_tmp)
    }
  }
}

# Plot # introductions with increasing # focal sequences
p <- ggplot(
  data = subsample_results,
  aes(x = paste0(subsample * 100, "%\n(n=", n_focal_seqs, ")"))) +
  geom_boxplot(aes(y = n_singletons, color = "No. singletons")) +
  geom_boxplot(aes(y = n_chains, color = "No. transmission chains")) +
  geom_boxplot(aes(y = n_chains + n_singletons, color = "No. total introductions")) +
  labs(x = "Sub-sampling intensity", y = "Count") + 
  scale_color_discrete(name = element_blank()) +
  facet_grid(. ~ chains_assumption, labeller = as_labeller(chain_assumption_labs)) + 
  shared_theme +
  scale_y_continuous(limits = c(0, NA))

show(p)

ggsave(
  filename = "figures/fig_SX_sensitivity_subsampling.png",
  width = double_col_width * 1.4,
  height = single_col_width * 0.75, 
  units = "cm"
)
```

# Compare transmission chain summary statistics across context set sizes, chains assumption

```{r}
is_first <- T
for (i in 1:length(results)) {
  res_desc <- names(results)[i]
  chains_temp <- results[[i]]$chains %>% mutate(res_desc = res_desc)
  if (is_first) {
    is_first <- F
    chains_all <- chains_temp
  } else {
    chains_all <- rbind(chains_all, chains_temp)
  }
}

to_plot <- chains_all %>%
  tidyr::separate(res_desc, into = c("sim_context", "rep"), sep = "x_rep") %>%
  mutate(sim_context = as.numeric(sim_context)) %>%
  group_by(sim_context, rep, chains_assumption) %>%
  summarize(
    mean_size = mean(size),
    median_size = median(size),
    number_chains = n(),
    number_trees = length(unique(tree)),
    .groups = "drop")

to_plot_w_runtime <- merge(
  x = to_plot,
  y = relevant_run_info,
  all.x = T)  # collated from Euler job finished emails, see results_all/run_info.csv

n_chain_scale_factor <- 200
ggplot(
  data = to_plot_w_runtime,
  aes(x = sim_context, shape = as.character(rep))) + 
  geom_point(aes(y = mean_size, color = "Mean chain size")) + 
  geom_point(aes(y = median_size, color = "Median chain size")) + 
  geom_point(aes(y = number_chains / n_chain_scale_factor, color = paste("Number chains /", n_chain_scale_factor))) + 
  geom_point(aes(y = runtime_hr, color = "Runtime (hours)")) + 
  # geom_point(aes(y = number_trees / 5, color = "Number lineage trees / 5")) +
  facet_grid(. ~ chains_assumption, labeller = as_labeller(chain_assumption_labs)) + 
  shared_theme + 
  scale_shape(name = "Replicate") + 
  scale_color_discrete(name = "Statistic") +
  scale_x_continuous(breaks = c(1, 2, 3), labels = c("1:1", "2:1", "3:1")) + 
  labs(x = "Ratio of foreign context to focal Swiss sequences", y = "Count")

ggsave(
  filename = "figures/fig_SX_sensitivity_context_set_size.png",
  width = double_col_width,
  height = single_col_width * 0.75, 
  units = "cm"
)
``` 

# Load alternate chain data for chosen context set ratio

```{r}
load_alternative_chains <- function(
  prefix = paste0("results_all/", date, "_for_supplement_sim_"),
  suffix = "_rep_",
  reps = c("1", "2", "3"),
  values = c("2")
) {
  is_first <- T
  for (value in values) {
    for (rep in reps) {
      fp <- paste(prefix, value, suffix, rep, sep = "")
      print(paste("Loading alternative chain results in", fp))
      chain_dirs <- list.files(path = paste(fp, "tmp", sep = "/"), pattern = "chains_m")
      print(chain_dirs)
      for (dir in chain_dirs) {
        chains_temp <- rbind(
          load_chain_asr_data(l = T, workdir = fp, chains_only = T, chains_dirname = dir) %>% mutate(chains_assumption = "min"),
          load_chain_asr_data(l = F, workdir = fp, chains_only = T, chains_dirname = dir) %>% mutate(chains_assumption = "max")) %>%
          mutate(chain_desc = dir, res_desc = paste(value, "x_rep", case_when(rep == "" ~ "0", T ~ rep), sep = ""))
        if (is_first) {
          alternative_chains_all <- chains_temp
          is_first <- F
        } else {
          alternative_chains_all <- rbind(alternative_chains_all, chains_temp)
        }
      }
    }
  }
  return(alternative_chains_all)
}

alternative_chains_all <- load_alternative_chains()
```

# Compare transmission chain summary statistics across chain definitions, chains assumption

```{r}
to_plot_2 <- alternative_chains_all %>%
  tidyr::separate(res_desc, into = c("sim_context", "rep"), sep = "x_rep") %>%
  tidyr::separate(chain_desc, into = c("m", "p"), sep = "_p_") %>%
  mutate(
    sim_context = as.numeric(sim_context), rep = as.numeric(rep),
    m = as.numeric(gsub(m, pattern = "chains_m_", replacement = "")), p = as.character(p)) %>%
  group_by(rep, m, p, chains_assumption) %>%
  summarize(
    mean_size = mean(size),
    median_size = median(size),
    max_size = max(size),
    number_chains = n(),
    number_trees = length(unique(tree)),
    .groups = "drop")

ggplot(
  data = to_plot_2,
  aes(x = m, shape = as.character(rep))) +
  geom_point(aes(y = mean_size, color = "Mean chain size")) +
  # geom_point(aes(y = max_size, color = "Largest chain")) +
  geom_point(aes(y = median_size, color = "Median chain size")) + 
  geom_point(aes(y = number_chains / 10, color = "Number chains / 10")) +
  facet_grid(
    p ~ chains_assumption, 
    labeller = as_labeller(x = c("0" = "0", "1" = "1", "2" = "2", "3" = "3", "4" = "4", chain_assumption_labs))) + 
  shared_theme + 
  scale_shape(name = "Replicate") + 
  scale_color_discrete(name = "Statistic") +
  scale_y_continuous(sec.axis = dup_axis(
    name = "Maximum consecutive exports in transmission chain",
    breaks = NULL, labels = NULL)) +   # produces lots of warnings about min(x) and max(x) but the points/axes on the plot are not affected
  labs(x = "Maximum exported lineages in transmission chain", y = "Count")

ggsave(
  filename = "figures/fig_SX_sensitivity_chain_defn.png",
  width = double_col_width,
  height = single_col_width * 1.5, 
  units = "cm"
)
```
