---
title: "Plot introductions vs. European incidence"
author: nadeaus
date: 12.10.21
output: html_notebook
---

This script is to see if the relationship between Europe-wide incidence and estimated imports into Switzerland changes upon the Swiss border closures.

```{r, setup, include=FALSE}
knitr::opts_knit$set(root.dir = "/Users/nadeaus/Repos/cov-swiss-phylogenetics")
knitr::opts_chunk$set(root.dir = "/Users/nadeaus/Repos/cov-swiss-phylogenetics")
```

```{r, include=FALSE}
require(dplyr)
require(tidyr)
require(ggplot2)
require(cowplot)
library(lubridate)
source("../sars_cov_2/grapevine/database/R/utility.R")
source("../sars_cov_2/grapevine/utility_functions.R")
source("../sars_cov_2/grapevine/generate_figures/functions.R")
source("scripts/figures_shared_vars.R")
```

Load grapevine data

```{r}
workdir <- "results_main"
outdir <- paste(workdir, "output", sep = "/")
outdir <- "figures"
grapevine_results <- load_grapevine_results(
  workdir = workdir,
  min_chain_size = 1,
  viollier_only = F)
```

Load case data for European countries

```{r}
CASE_COUNT_LINK <- "https://opendata.ecdc.europa.eu/covid19/casedistribution/csv/"
cases_raw <- read.csv(url(CASE_COUNT_LINK), na.strings = "", fileEncoding = "UTF-8-BOM") %>%
  filter(continentExp == "Europe") %>%
  select(countryterritoryCode, dateRep, cases) %>%
  mutate(date = as.Date(dateRep, "%d/%m/%Y")) %>%
  filter(date <= as.Date("2020-12-01"))

cases_summary <- cases_raw %>%
        mutate(country = case_when(
                countryterritoryCode == "CHE" ~ "Switzerland",
                countryterritoryCode == "FRA" ~ "France",
                countryterritoryCode == "DEU" ~ "Germany",
                countryterritoryCode == "ITA" ~ "Italy",
                countryterritoryCode == "AUT" ~ "Austria",
                T ~ "Other European")) %>%
        group_by(date, country) %>%
        summarize(cases = sum(cases), .groups = "drop") %>%
        group_by(country) %>%
        arrange(date) %>%
        mutate(weekly_avg_new_cases = zoo::rollmean(cases,7, align = "center", na.pad = T))
```

Summarize introductions, their persistence and merge with case data

```{r}
chain_summary_stats <- grapevine_results$samples %>%
  group_by(tree, chains_assumption, chain_idx) %>%
  summarize(first_sample_date = min(date),
            last_sample_date = max(date),
            .groups = "drop") %>%
  mutate(time_to_last_sample = difftime(last_sample_date, first_sample_date, units = "days")) %>%
  full_join(y = grapevine_results$chains, by = c("tree", "chains_assumption", "chain_idx"))

#' Returns the date of the Sunday of the week.
#' Inspired by: https://stackoverflow.com/questions/32434549/how-to-find-next-particular-day
get_start_of_week <- function(date) {
  .day <- wday(date, label = TRUE)
  sunday <- date + days(1 - as.numeric(.day))
  return(sunday)
}

introduction_summary_tmp <- chain_summary_stats %>%  # weekly summary
  mutate(date = get_start_of_week(first_sample_date)) %>%
  group_by(date, chains_assumption) %>%
  summarise(
    introductions_by_first_sample_date = n(), .groups = "drop") %>%
  mutate(country = "Switzerland")

# exclude undefined values for persistence
introduction_summary <- introduction_summary_tmp
max_date <- max(introduction_summary$date) - 60
introduction_summary[introduction_summary$date > max_date, "frac_60_day_persisters"] <- NA

persistence_summary <- chain_summary_stats %>%  # monthly summary
  mutate(date = as.Date(format(first_sample_date, "%Y-%m-01"))) %>%
  group_by(date, chains_assumption) %>%
  summarise(
    frac_60_day_persisters = sum(time_to_last_sample >= 60) / n()) %>%
  mutate(country = "Switzerland")

introduction_summary <- merge(x = introduction_summary_tmp, y = persistence_summary, by = c("date", "chains_assumption", "country"), all = T)

introduction_summary_wide <- introduction_summary %>%
        pivot_wider(names_from = "chains_assumption", values_from = c(
                "introductions_by_first_sample_date",
                "frac_60_day_persisters"))

combined_data <- cases_summary %>% full_join(introduction_summary_wide, by = c("date", "country"))
```

Plot introductions vs. persistence, comparison to incidence

```{r}

country_color_scale <- scale_color_manual(
  values = c("Switzerland" = "#E69F00", "France" = "#56B4E9", "Germany" = "#F0E442", "Italy" = "#009E73", "Other European" = "#CC79A7", "Austria" = "black"),
  name = element_blank())

incidence_plot <- ggplot(data = combined_data %>%
        filter(date <= as.Date("2020-04-15"), date >= as.Date("2020-02-15")),
        aes(x = date, color = country)) +
        geom_line(aes(y = weekly_avg_new_cases)) +
        scale_x_date(date_breaks = "1 month", date_labels = "%b.") +
        labs(y = "Confirmed cases\n(weekly average)", x = "") +
        shared_theme +
        country_color_scale

# Extract legend to plot seperately
incidence_legend <- get_legend(
  # create some space to the left of the legend
  incidence_plot +
    guides(color = guide_legend(nrow = 1)) +
    theme(legend.position = "bottom") +
    guides(fill=guide_legend(nrow=2,byrow=TRUE)))
incidence_plot <- incidence_plot + theme(legend.position = "none")
incidence_plot_v2 <- incidence_plot +
  geom_vline(xintercept = as.Date("2020-03-13"), linetype = "dashed")

# Manipulate data: sometimes max chains has more persisters in a week, sometimes min chains assumption
introduction_summary_v2 <- rbind(
  introduction_summary %>%
    group_by(date) %>%
    arrange(frac_60_day_persisters, chains_assumption) %>%
    mutate(which_most = chains_assumption[[1]],
           min = frac_60_day_persisters[1],
           max = frac_60_day_persisters[2],
           metric = "Fraction of new introductions that persist 60 days, by month") %>%
    filter(date < as.Date("2020-10-01")),
  introduction_summary %>%
    group_by(date) %>%
    arrange(-introductions_by_first_sample_date) %>%
    mutate(which_most = chains_assumption[[1]],
           max = introductions_by_first_sample_date[1],
           min = introductions_by_first_sample_date[2],
           metric = "Number of new introductions, by week")) %>%
  mutate(metric = factor(x = metric, levels = c("Number of new introductions, by week", "Fraction of new introductions that persist 60 days, by month")))

highlight_data <- data.frame(
  date_start = as.Date(c("2020-03-13", "2020-03-17")),
  date_end = as.Date(c("2020-06-15", "2020-04-27")),
  metric = c("Number of new introductions, by week", "Fraction of new introductions that persist 60 days, by month"),
  event = c("Borders closed", "Partial lockdown")) %>%
  mutate(metric = factor(x = metric, levels = c("Number of new introductions, by week", "Fraction of new introductions that persist 60 days, by month")))

fill_scale <- scale_fill_manual(values = c(
  "Borders closed" = "black",
  "Partial lockdown" = "grey"))

p1 <- ggplot(
  data = introduction_summary_v2,
  aes(x = date)) +
  geom_errorbar(aes(ymin = min, ymax = max),  width = 5) +
  scale_x_date(date_breaks = "1 month", date_labels = "%b.", limits = as.Date(c("2020-01-28", "2020-12-03"))) +
  ylim(0, NA) +
  xlab(NULL) + ylab(NULL) +
  facet_wrap(metric ~ ., ncol = 1, scales = "free_y", ) +
  shared_theme +
  fill_scale +
  theme(legend.position = "bottom", legend.title = element_blank()) +
  geom_rect(inherit.aes = F, data = highlight_data, aes(xmin = date_start, xmax = date_end, ymin = -Inf, ymax = Inf, fill = event), alpha = 0.3)

p2 <- incidence_plot_v2 +  # use incidence_plot for no dashed line and area instead
  guides(color = guide_legend(nrow = 1)) +
  theme(legend.position = "bottom") +
  guides(color=guide_legend(nrow=3,byrow=TRUE))

plot_grid(p1, p2, ncol = 2, labels = "AUTO", rel_widths = c(1, 0.7))

ggsave("figures/introductions_and_persistence.png",
       width = double_col_width, height = single_col_width, units = "cm")
```

Make this quantitative: introductions ~ europe incidence (until border closure date, with some delay)
```{r}
# Test different lags from European incidence to sampled introduction,
# up to 18 days based on 10-day infectious period, LdP's UK estimate of 10-18 day introduction to genome sample delay
case_data_base <- cases_raw %>%
        filter(countryterritoryCode != "CHE",
               countryterritoryCode %in% c("ITA", "FRA", "DEU", "AUT")) %>%
        group_by(date) %>%
        summarize(cases = sum(cases), .groups = "drop") %>%
        arrange(date) %>%
        mutate(weekly_avg_new_cases = zoo::rollmean(cases,7, align = "center", na.pad = T)) %>%
        select(-cases)

plausible_delays <- seq(from = 0, to = 18, by = 1)
is_first <- T
for (delay in plausible_delays) {
  cases_summary_for_model <- case_data_base %>% mutate(date_current = date, date = date - delay)  # introductions ~ incidence lagged by delay days

  model_data <- cases_summary_for_model %>%
          right_join(introduction_summary_wide %>% select(-c(country, starts_with("frac"))), by = "date")

  model_max <- lm(
          data = model_data %>% filter(date < as.Date("2020-03-13")),
          formula = introductions_by_first_sample_date_max ~ weekly_avg_new_cases)
  model_min <- lm(
          data = model_data %>% filter(date < as.Date("2020-03-13")),
          formula = introductions_by_first_sample_date_min ~ weekly_avg_new_cases)

  # Thanks https://stackoverflow.com/questions/43123462/how-to-obtain-rmse-out-of-lm-result
  RMSE_max <- sqrt(crossprod(model_max$residuals) / length(model_max$residuals)) # root mean squared error
  RMSE_min <- sqrt(crossprod(model_min$residuals) / length(model_min$residuals))

  cases_coeff_max <- model_max$coefficients["weekly_avg_new_cases"]
  cases_coeff_min <- model_min$coefficients["weekly_avg_new_cases"]

  results_tmp <- data.frame(
          delay = delay, RMSE_max = RMSE_max, RMSE_min = RMSE_min,
          cases_coeff_max = cases_coeff_max, cases_coeff_min = cases_coeff_min)

  if (is_first) {
    results <- results_tmp
    is_first <- F
  } else {
    results <- rbind(results, results_tmp)
  }
}

# Extract best-fit delays and coefficients
cases_coeff_max <- unlist(results %>% top_n(n = 1, wt = -RMSE_max) %>% select(cases_coeff_max))
cases_coeff_min <- unlist(results %>% top_n(n = 1, wt = -RMSE_min) %>% select(cases_coeff_min))

cases_delay_max <- unlist(results %>% top_n(n = 1, wt = -RMSE_max) %>% select(delay))
cases_delay_min <- unlist(results %>% top_n(n = 1, wt = -RMSE_min) %>% select(delay))

# Plot best-fit models and predictions
data_max <- case_data_base %>%
        mutate(date_current = date, date = date - cases_delay_max) %>%
        right_join(introduction_summary_wide %>% select(-c(country, starts_with("frac"))), by = "date") %>%
        mutate(predictions_max = weekly_avg_new_cases *  cases_coeff_max)

data_min <- case_data_base %>%
        mutate(date_current = date, date = date - cases_delay_min) %>%
        right_join(introduction_summary_wide %>% select(-c(country, starts_with("frac"))), by = "date") %>%
        mutate(predictions_min = weekly_avg_new_cases *  cases_coeff_min)

introductions_vs_indicence_data <- merge(data_max, data_min,
              by = c("date", "introductions_by_first_sample_date_max", "introductions_by_first_sample_date_min"))

introductions_vs_indicence_model <- ggplot(
        data = introductions_vs_indicence_data %>% filter(date <= as.Date("2020-07-01")),
        aes(x = date)) +
        geom_errorbar(aes(ymin = introductions_by_first_sample_date_min, ymax = introductions_by_first_sample_date_max, color = "Estimated"),  width = 5) +
        geom_ribbon(aes(ymin = predictions_min, ymax = predictions_max, fill = "Predicted"), alpha = 0.5) +
        geom_vline(xintercept = as.Date("2020-03-13"), linetype = "dashed") +
        geom_vline(xintercept = as.Date("2020-06-15"), linetype = "dashed") +
        scale_x_date(date_breaks = "1 week", date_labels = "%b. %d", limits = c(as.Date("2020-02-24"), as.Date("2020-07-01"))) +
        scale_fill_manual(values = c("Predicted" = "grey70"), name = element_blank()) +
        scale_color_manual(values = c("Estimated" = "black"), name = element_blank()) +
        shared_theme +
        theme(axis.text.x = element_text(angle = 90, vjust = 0.5), legend.spacing.y = unit(0, "cm")) +
        labs(x = element_blank(), y = "\nNew introductions")
# ggsave(plot = introductions_vs_indicence_model, file = "figures/introductions_vs_indicence_model.png",
#        width = single_col_width, height = single_col_width, units = "cm")
```

Write out the model variables, number of introductions averted during the lockdown
```{r}
prediced_introductions_averted <- introductions_vs_indicence_data %>% filter(date >= as.Date("2020-03-13"), date <= as.Date("2020-06-15")) %>%
        summarise(predicted_introductions_averted_max = sum(predictions_max) - sum(introductions_by_first_sample_date_max, na.rm = T),
                  predicted_introductions_averted_min = sum(predictions_min) - sum(introductions_by_first_sample_date_min, na.rm = T))

prediced_introductions_averted_as_per <- introductions_vs_indicence_data %>% filter(date >= as.Date("2020-03-13"), date <= as.Date("2020-06-15")) %>%
        summarise(predicted_introductions_averted_max_asper =
                          (sum(predictions_max) - sum(introductions_by_first_sample_date_max, na.rm = T)) / sum(predictions_max),
                  predicted_introductions_averted_min_asper =
                          (sum(predictions_min) - sum(introductions_by_first_sample_date_min, na.rm = T)) / sum(predictions_min))

introsavertedmax <- unlist(prediced_introductions_averted$predicted_introductions_averted_max)
introsavertedmin <- unlist(prediced_introductions_averted$predicted_introductions_averted_min)

introsavertedaspermax <- unlist(prediced_introductions_averted_as_per$predicted_introductions_averted_max_asper)
introsavertedaspermin <- unlist(prediced_introductions_averted_as_per$predicted_introductions_averted_min_asper)

con <- file("manuscript/intoductions_by_incidence_model.tex", open = "w")
writeLines(text = paste0("\\newcommand\\casescoeffmax{", signif(cases_coeff_max, digits = 2), "}"), con = con)
writeLines(text = paste0("\\newcommand\\casescoeffmin{", signif(cases_coeff_min, digits = 2), "}"), con = con)
writeLines(text = paste0("\\newcommand\\casesdelaymax{", cases_delay_max, "}"), con = con)
writeLines(text = paste0("\\newcommand\\casesdelaymin{", cases_delay_min, "}"), con = con)
writeLines(text = paste0("\\newcommand\\introsavertedmax{", round(introsavertedmax, digits = 0), "}"), con = con)
writeLines(text = paste0("\\newcommand\\introsavertedmin{", round(introsavertedmin, digits = 0), "}"), con = con)
writeLines(text = paste0("\\newcommand\\introsavertedaspermax{", round(introsavertedaspermax * 100, digits = 0), "}"), con = con)
writeLines(text = paste0("\\newcommand\\introsavertedaspermin{", round(introsavertedaspermin * 100, digits = 0), "}"), con = con)
close(con)
```

Quantifying persistence around the lockdown: measure mean time to last sample for introductions spreading each day
```{r}
# Mean and Q1, Q3 lifespan of introductions spreading at each day in the sample period
is_first <- T
dates <- seq.Date(from = as.Date("2020-02-01"), to = as.Date("2020-12-01"), by = 1)
for (idx in seq_along(dates)) {
  start_date <- dates[idx]
  chains_on_date_data <- chain_summary_stats %>%
          filter(first_sample_date <= start_date, last_sample_date >= start_date) %>%
          mutate(days_continued_sampled = as.integer(last_sample_date - start_date)) %>%  # length of continued sampling after start_date
          select(chains_assumption, days_continued_sampled) %>%
          mutate(date = start_date)
  if (is_first) {
    persistence_results <- chains_on_date_data
    is_first <- F
  } else {
    persistence_results <- rbind(persistence_results, chains_on_date_data)
  }
}

# Smooth results
is_first <- T
dates <- seq.Date(from = as.Date("2020-02-01"), to = as.Date("2020-12-01"), by = 1)
window_size <- 0  # end inclusive, so estimates are based on time from x to last_sample_date distributions summed over date - 3 days <= x <= date + 3 days
for (idx in seq_along(dates)) {
  start_date <- dates[idx]
  smooth_results <- persistence_results %>%
          filter(date <= start_date + window_size, date >= start_date - window_size) %>%
          group_by(chains_assumption) %>%
          summarize(n = n(),
                    median = quantile(x = days_continued_sampled, probs = c(0.25, 0.5, 0.75))[2],
                    Q1 = quantile(x = days_continued_sampled, probs = c(0.25, 0.5, 0.75))[1],
                    Q3 = quantile(x = days_continued_sampled, probs = c(0.25, 0.5, 0.75))[3]) %>%
          mutate(date = start_date)
  if (is_first) {
    persistence_results_smooth <- smooth_results
    is_first <- F
  } else {
    persistence_results_smooth <- rbind(persistence_results_smooth, smooth_results)
  }
}

persisence_over_time <- ggplot(data = persistence_results_smooth %>% filter(date <= as.Date("2020-07-01")), aes(x = date, fill = chains_assumption)) +
        geom_line(aes(y = median, color = chains_assumption)) +
        geom_ribbon(aes(ymin = Q1, ymax = Q3), alpha = 0.3) +
        geom_vline(xintercept = as.Date("2020-03-17"), linetype = "dashed") +
        geom_vline(xintercept = as.Date("2020-04-27"), linetype = "dashed") +
        scale_x_date(date_breaks = "1 week", date_labels = "%b. %d", limits = c(as.Date("2020-02-24"), as.Date("2020-07-01"))) +
        scale_fill_manual(labels = chain_assumption_labs, values = chains_assumption_colors, aesthetics = c("fill", "color"), name = element_blank()) +
        shared_theme +
        theme(axis.text.x = element_text(angle = 90, vjust = 0.5)) +
        labs(x = element_blank(), y = "\nPersistence (days)")
# ggsave(plot = persisence_over_time, filename = "figures/persisence_over_time.png",
#        width = single_col_width, height = single_col_width, units = "cm")
```

Write out the persistence of introductions at the start of lockdown, post-lockdown peak
```{r}
lockdown_start_persistence <- persistence_results_smooth %>%
        filter(date == as.Date("2020-03-17"))
lockdown_end_persistence <- persistence_results_smooth %>%
        filter(date >= as.Date("2020-04-27")) %>%
        group_by(chains_assumption) %>%
        top_n(n = 1, wt = Q1)

con <- file("manuscript/persistence.tex", open = "w")
medpersistenceatlockdownmin <- unlist(lockdown_start_persistence[lockdown_start_persistence$chains_assumption == "min", "median"])
medpersistenceatlockdownmax <- unlist(lockdown_start_persistence[lockdown_start_persistence$chains_assumption == "max", "median"])
writeLines(text = paste0("\\newcommand\\medpersistenceatlockdownmin{", medpersistenceatlockdownmin, "}"), con = con)
writeLines(text = paste0("\\newcommand\\medpersistenceatlockdownmax{", medpersistenceatlockdownmax, "}"), con = con)

qonepersistenceatlockdownmin <- unlist(lockdown_start_persistence[lockdown_start_persistence$chains_assumption == "min", "Q1"])
qonepersistenceatlockdownmax <- unlist(lockdown_start_persistence[lockdown_start_persistence$chains_assumption == "max", "Q1"])
writeLines(text = paste0("\\newcommand\\qonepersistenceatlockdownmin{", qonepersistenceatlockdownmin, "}"), con = con)
writeLines(text = paste0("\\newcommand\\qonepersistenceatlockdownmax{", qonepersistenceatlockdownmax, "}"), con = con)

qthreepersistenceatlockdownmin <- unlist(lockdown_start_persistence[lockdown_start_persistence$chains_assumption == "min", "Q3"])
qthreepersistenceatlockdownmax <- unlist(lockdown_start_persistence[lockdown_start_persistence$chains_assumption == "max", "Q3"])
writeLines(text = paste0("\\newcommand\\qthreepersistenceatlockdownmin{", qthreepersistenceatlockdownmin, "}"), con = con)
writeLines(text = paste0("\\newcommand\\qthreepersistenceatlockdownmax{", qthreepersistenceatlockdownmax, "}"), con = con)

medpersistenceatpeakmin <- unlist(lockdown_end_persistence[lockdown_end_persistence$chains_assumption == "min", "median"])
medpersistenceatpeakmax <- unlist(lockdown_end_persistence[lockdown_end_persistence$chains_assumption == "max", "median"])
writeLines(text = paste0("\\newcommand\\medpersistenceatpeakmin{", medpersistenceatpeakmin, "}"), con = con)
writeLines(text = paste0("\\newcommand\\medpersistenceatpeakmax{", medpersistenceatpeakmax, "}"), con = con)

qonepersistenceatpeakmin <- unlist(lockdown_end_persistence[lockdown_end_persistence$chains_assumption == "min", "Q1"])
qonepersistenceatpeakmax <- unlist(lockdown_end_persistence[lockdown_end_persistence$chains_assumption == "max", "Q1"])
writeLines(text = paste0("\\newcommand\\qonepersistenceatpeakmin{", qonepersistenceatpeakmin, "}"), con = con)
writeLines(text = paste0("\\newcommand\\qonepersistenceatpeakmax{", qonepersistenceatpeakmax, "}"), con = con)

qthreepersistenceatpeakmin <- unlist(lockdown_end_persistence[lockdown_end_persistence$chains_assumption == "min", "Q3"])
qthreepersistenceatpeakmax <- unlist(lockdown_end_persistence[lockdown_end_persistence$chains_assumption == "max", "Q3"])
writeLines(text = paste0("\\newcommand\\qthreepersistenceatpeakmin{", qthreepersistenceatpeakmin, "}"), con = con)
writeLines(text = paste0("\\newcommand\\qthreepersistenceatpeakmax{", qthreepersistenceatpeakmax, "}"), con = con)
close(con)
```

Format comparative figure
```{r}
plot_grid(introductions_vs_indicence_model, persisence_over_time,
          nrow = 2, align = "v", axis = "tb", labels = "AUTO")

ggsave("figures/introductions_and_persistence_v2.png",
       width = double_col_width, height = single_col_width, units = "cm")
```
