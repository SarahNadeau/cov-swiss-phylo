---
title: "Plot introductions vs. European incidence"
author: nadeaus
date: 12.10.21
output: html_notebook
---

This script is to see if the relationship between Europe-wide incidence and estimated imports into Switzerland changes upon the Swiss border closures.

```{r, include=FALSE}
require(dplyr)
require(tidyr)
require(ggplot2)
require(cowplot)
require(zoo)
library(lubridate)

source("../sars_cov_2/grapevine/utility_functions.R")
source("../sars_cov_2/grapevine/generate_figures/functions.R")
source("scripts/figures_shared_vars.R")
```

Load grapevine data

```{r}
workdir <- "results_all/2021-08-10_for_manuscript_rep_1"
outdir <- paste(workdir, "output", sep = "/")
outdir <- "figures"
grapevine_results <- load_grapevine_results(
  workdir = workdir,
  min_chain_size = 1,
  viollier_only = F)
```

Load case data for European countries

```{r}
CASE_COUNT_LINK <- "https://opendata.ecdc.europa.eu/covid19/casedistribution/csv/"
cases_raw <- read.csv(url(CASE_COUNT_LINK), na.strings = "", fileEncoding = "UTF-8-BOM") %>%
  filter(continentExp == "Europe") %>%
  select(countryterritoryCode, dateRep, cases) %>%
  mutate(date = as.Date(dateRep, "%d/%m/%Y")) %>%
  filter(date <= as.Date("2020-12-01"))

cases_summary <- cases_raw %>%
        mutate(country = case_when(
                countryterritoryCode == "CHE" ~ "Switzerland",
                countryterritoryCode == "FRA" ~ "France",
                countryterritoryCode == "DEU" ~ "Germany",
                countryterritoryCode == "ITA" ~ "Italy",
                countryterritoryCode == "AUT" ~ "Austria",
                T ~ "Other European")) %>%
        group_by(date, country) %>%
        summarize(cases = sum(cases), .groups = "drop") %>%
        group_by(country) %>%
        arrange(date) %>%
        mutate(weekly_avg_new_cases = zoo::rollmean(cases,7, align = "center", na.pad = T))
```

Summarize introductions, their persistence and merge with case data

```{r}
chain_summary_stats <- grapevine_results$samples %>%
  group_by(tree, chains_assumption, chain_idx) %>%
  summarize(first_sample_date = min(date),
            last_sample_date = max(date),
            .groups = "drop") %>%
  mutate(time_to_last_sample = difftime(last_sample_date, first_sample_date, units = "days")) %>%
  full_join(y = grapevine_results$chains, by = c("tree", "chains_assumption", "chain_idx"))

#' Returns the date of the Sunday of the week.
#' Inspired by: https://stackoverflow.com/questions/32434549/how-to-find-next-particular-day
get_start_of_week <- function(date) {
  .day <- wday(date, label = TRUE)
  sunday <- date + days(1 - as.numeric(.day))
  return(sunday)
}

introduction_summary_tmp <- chain_summary_stats %>%  # weekly summary
  mutate(date = get_start_of_week(first_sample_date)) %>%
  group_by(date, chains_assumption) %>%
  summarise(
    introductions_by_first_sample_date = n(), .groups = "drop") %>%
  mutate(country = "Switzerland")

# exclude undefined values for persistence
introduction_summary <- introduction_summary_tmp
max_date <- max(introduction_summary$date) - 60
introduction_summary[introduction_summary$date > max_date, "frac_60_day_persisters"] <- NA

persistence_summary <- chain_summary_stats %>%  # monthly summary
  mutate(date = as.Date(format(first_sample_date, "%Y-%m-01"))) %>%
  group_by(date, chains_assumption) %>%
  summarise(
    frac_60_day_persisters = sum(time_to_last_sample >= 60) / n()) %>%
  mutate(country = "Switzerland")

introduction_summary <- merge(x = introduction_summary_tmp, y = persistence_summary, by = c("date", "chains_assumption", "country"), all = T)

introduction_summary_wide <- introduction_summary %>%
        pivot_wider(names_from = "chains_assumption", values_from = c(
                "introductions_by_first_sample_date",
                "frac_60_day_persisters"))

combined_data <- cases_summary %>% full_join(introduction_summary_wide, by = c("date", "country"))
```

Plot introductions through time, persistence through time
```{r}
introduction_summary_v2 <- introduction_summary %>%
                group_by(date) %>%
                arrange(-introductions_by_first_sample_date) %>%
                mutate(which_most = chains_assumption[[1]],
                       max = introductions_by_first_sample_date[1],
                       min = introductions_by_first_sample_date[2])

persistence_summary_v2 <- persistence_summary %>%
    group_by(date) %>%
    arrange(frac_60_day_persisters, chains_assumption) %>%
    mutate(which_most = chains_assumption[[1]],
           min = frac_60_day_persisters[1],
           max = frac_60_day_persisters[2]) %>%
    filter(date < as.Date("2020-10-01"))

highlight_data <- data.frame(
        date_start = as.Date(c("2020-03-13", "2020-03-17")),
        date_end = as.Date(c("2020-06-15", "2020-04-27")),
        event = c("Borders closed", "Partial lockdown"))

measures_fill_scale <- scale_fill_manual(values = c(
        "Borders closed" = "black",
        "Partial lockdown" = "grey"))

introductions_through_time <- ggplot(
        data = introduction_summary_v2,
        aes(x = date)) +
        geom_errorbar(aes(ymin = min, ymax = max),  width = 5) +
        scale_x_date(date_breaks = "1 month", date_labels = "%b.", limits = as.Date(c("2020-01-28", "2020-12-03"))) +
        ylim(0, NA) +
        xlab(NULL) + ylab("New introductions") +
        shared_theme +
        measures_fill_scale +
        theme(legend.position = "bottom", legend.title = element_blank()) +
        geom_rect(inherit.aes = F, data = highlight_data %>% filter(event == "Borders closed"),
                  aes(xmin = date_start, xmax = date_end, ymin = -Inf, ymax = Inf, fill = event), alpha = 0.3)

persistence_through_time <- ggplot(
        data = persistence_summary_v2,
        aes(x = date)) +
        geom_errorbar(aes(ymin = min, ymax = max),  width = 5) +
        scale_x_date(date_breaks = "1 month", date_labels = "%b.", limits = as.Date(c("2020-01-28", "2020-12-03"))) +
        ylim(0, NA) +
        xlab(NULL) + ylab("Fraction of\nnew introductions\nthat persist 60 days") +
        shared_theme +
        measures_fill_scale +
        theme(legend.position = "bottom", legend.title = element_blank()) +
        geom_rect(inherit.aes = F, data = highlight_data %>% filter(event == "Partial lockdown"),
                  aes(xmin = date_start, xmax = date_end, ymin = -Inf, ymax = Inf, fill = event), alpha = 0.3)

introductions_through_time
persistence_through_time

# Extract legend to plot seperately
intervention_legend <- get_legend(
        # create some space to the left of the legend
        introductions_through_time +
                guides(color = guide_legend(nrow = 1)) +
                theme(legend.position = "bottom"))

introductions_through_time <- introductions_through_time + theme(legend.position = "none")
persistence_through_time <- persistence_through_time + theme(legend.position = "none")
```


Make this quantitative: introductions ~ europe incidence (until border closure date, with some delay)
```{r}
# Test different lags from European incidence to sampled introduction,
# up to 18 days based on 10-day infectious period, LdP's UK estimate of 10-18 day introduction to genome sample delay
case_data_base <- cases_raw %>%
        filter(countryterritoryCode != "CHE",
               # ) %>%  # for all Europe
               countryterritoryCode %in% c("ITA", "FRA", "DEU", "AUT")) %>%  # for only neighboring countries
        group_by(date) %>%
        summarize(cases = sum(cases), .groups = "drop") %>%
        arrange(date) %>%
        mutate(weekly_avg_new_cases = zoo::rollmean(cases,7, align = "center", na.pad = T)) %>%
        select(-cases)

close_date <- as.Date("2020-03-13")
re_open_date <- as.Date("2020-06-15")
end_summer_holiday_date <- as.Date("2020-08-28")
plausible_delays <- seq(from = 0, to = 18, by = 1)
is_first <- T
for (delay in plausible_delays) {
  cases_summary_for_model <- case_data_base %>% mutate(date_current = date, date = date - delay)  # introductions ~ incidence lagged by delay days

  model_data <- cases_summary_for_model %>%
          right_join(introduction_summary_wide %>% select(-c(country, starts_with("frac"))), by = "date")

  model_max <- lm(
          data = model_data %>% filter(date < close_date),
          formula = introductions_by_first_sample_date_max ~ weekly_avg_new_cases)
  model_min <- lm(
          data = model_data %>% filter(date < close_date),
          formula = introductions_by_first_sample_date_min ~ weekly_avg_new_cases)
  # Reviewer requests results from model fit after re-opening as well
  model_max_fit_after <- lm(
          data = model_data %>% filter(date < close_date | (date >= re_open_date & date < end_summer_holiday_date)),
          formula = introductions_by_first_sample_date_max ~ weekly_avg_new_cases)
  model_min_fit_after <- lm(
          data = model_data %>% filter(date < close_date | (date >= re_open_date & date < end_summer_holiday_date)),
          formula = introductions_by_first_sample_date_min ~ weekly_avg_new_cases)

  # Thanks https://stackoverflow.com/questions/43123462/how-to-obtain-rmse-out-of-lm-result
  RMSE_max <- sqrt(crossprod(model_max$residuals) / length(model_max$residuals)) # root mean squared error
  RMSE_min <- sqrt(crossprod(model_min$residuals) / length(model_min$residuals))
  RMSE_max_fit_after <- sqrt(crossprod(model_max_fit_after$residuals) / length(model_max_fit_after$residuals))
  RMSE_min_fit_after <- sqrt(crossprod(model_min_fit_after$residuals) / length(model_min_fit_after$residuals))

  cases_coeff_max <- model_max$coefficients["weekly_avg_new_cases"]
  cases_coeff_min <- model_min$coefficients["weekly_avg_new_cases"]
  cases_coeff_max_fit_after <- model_max_fit_after$coefficients["weekly_avg_new_cases"]
  cases_coeff_min_fit_after <- model_min_fit_after$coefficients["weekly_avg_new_cases"]

  results_tmp <- data.frame(
          delay = delay,
          RMSE_max = RMSE_max,
          RMSE_min = RMSE_min,
          RMSE_max_fit_after = RMSE_max_fit_after,
          RMSE_min_fit_after = RMSE_min_fit_after,
          cases_coeff_max = cases_coeff_max,
          cases_coeff_min = cases_coeff_min,
          cases_coeff_max_fit_after = cases_coeff_max_fit_after,
          cases_coeff_min_fit_after = cases_coeff_min_fit_after
  )

  if (is_first) {
    results <- results_tmp
    is_first <- F
  } else {
    results <- rbind(results, results_tmp)
  }
}

# Extract best-fit delays and coefficients
cases_coeff_max <- unlist(results %>% top_n(n = 1, wt = -RMSE_max) %>% select(cases_coeff_max))
cases_coeff_min <- unlist(results %>% top_n(n = 1, wt = -RMSE_min) %>% select(cases_coeff_min))
cases_coeff_max_fit_after <- unlist(
        results %>% top_n(n = 1, wt = -RMSE_max_fit_after) %>% select(cases_coeff_max_fit_after))
cases_coeff_min_fit_after <- unlist(
        results %>% top_n(n = 1, wt = -RMSE_min_fit_after) %>% select(cases_coeff_min_fit_after))

cases_delay_max <- unlist(results %>% top_n(n = 1, wt = -RMSE_max) %>% select(delay))
cases_delay_min <- unlist(results %>% top_n(n = 1, wt = -RMSE_min) %>% select(delay))
cases_delay_max_fit_after <- unlist(results %>% top_n(n = 1, wt = -RMSE_max_fit_after) %>% select(delay))
cases_delay_min_fit_after <- unlist(results %>% top_n(n = 1, wt = -RMSE_min_fit_after) %>% select(delay))

# Plot best-fit models and predictions
data_max <- case_data_base %>%
        mutate(date_current = date, date = date - cases_delay_max) %>%
        right_join(introduction_summary_wide %>% select(-c(country, starts_with("frac"))), by = "date") %>%
        mutate(predictions_max = weekly_avg_new_cases *  cases_coeff_max)
data_min <- case_data_base %>%
        mutate(date_current = date, date = date - cases_delay_min) %>%
        right_join(introduction_summary_wide %>% select(-c(country, starts_with("frac"))), by = "date") %>%
        mutate(predictions_min = weekly_avg_new_cases *  cases_coeff_min)
data_max_fit_after <- case_data_base %>%
        mutate(date_current = date, date = date - cases_delay_max_fit_after) %>%
        right_join(introduction_summary_wide %>% select(-c(country, starts_with("frac"))), by = "date") %>%
        mutate(predictions_max_fit_after = weekly_avg_new_cases *  cases_coeff_max_fit_after)
data_min_fit_after <- case_data_base %>%
        mutate(date_current = date, date = date - cases_delay_min_fit_after) %>%
        right_join(introduction_summary_wide %>% select(-c(country, starts_with("frac"))), by = "date") %>%
        mutate(predictions_min_fit_after = weekly_avg_new_cases *  cases_coeff_min_fit_after)

introductions_vs_indicence_data_1 <- merge(
        data_max, data_min,
        by = c("date", "introductions_by_first_sample_date_max", "introductions_by_first_sample_date_min"))
introductions_vs_indicence_data_2 <- merge(
        data_max_fit_after, data_min_fit_after,
        by = c("date", "introductions_by_first_sample_date_max", "introductions_by_first_sample_date_min"))
introductions_vs_indicence_data <- merge(
        introductions_vs_indicence_data_1, introductions_vs_indicence_data_2,
        by = c("date", "introductions_by_first_sample_date_max", "introductions_by_first_sample_date_min"))

introductions_vs_indicence_model <- ggplot(
        data = introductions_vs_indicence_data %>% filter(date <= end_summer_holiday_date),
        aes(x = date)) +
        geom_errorbar(aes(ymin = introductions_by_first_sample_date_min,
                          ymax = introductions_by_first_sample_date_max,
                          linetype = "Estimate range:\nfew to many introductions"),
                      width = 5) +
        geom_line(aes(y = predictions_min, linetype = "Null model")) +
        geom_line(aes(y = predictions_max, linetype = "Null model")) +
        # geom_line(aes(y = predictions_min_fit_after, linetype = "Null model fit after")) +
        # geom_line(aes(y = predictions_max_fit_after, linetype = "Null model fit after")) +
        scale_x_date(date_breaks = "1 week", date_labels = "%b. %d",
                     limits = c(as.Date("2020-02-24"), end_summer_holiday_date)) +
        scale_fill_manual(values = c("Predicted" = "grey70"), name = element_blank()) +
        scale_linetype_manual(values = c(
                "Null model" = "dashed",
                "Null model fit after" = "dotted",
                "Estimate range:\nfew to many introductions" = "solid")) +
        scale_color_manual(values = c("Estimate range:\nfew to many introductions" = "black"), name = element_blank()) +
        shared_theme +
        theme(axis.text.x = element_text(angle = 90, vjust = 0.5), legend.spacing.y = unit(0, "cm"),
              legend.title = element_blank()) +
        labs(x = element_blank(), y = "\nNew introductions") +
        geom_rect(inherit.aes = F, data = highlight_data %>% filter(event == "Borders closed"),
                  aes(xmin = date_start, xmax = date_end, ymin = -Inf, ymax = Inf),
                  fill = "black",
                  alpha = 0.3)

introductions_vs_indicence_model
```

Write out the model variables, number of introductions averted during the lockdown
```{r}
prediced_introductions_averted <- introductions_vs_indicence_data %>%
        filter(date >= as.Date("2020-03-13"), date <= as.Date("2020-06-15")) %>%
        summarise(predicted_introductions_averted_max = sum(predictions_max) - sum(introductions_by_first_sample_date_max, na.rm = T),
                  predicted_introductions_averted_min = sum(predictions_min) - sum(introductions_by_first_sample_date_min, na.rm = T),
                  predicted_introductions_averted_min_fit_after = sum(predictions_min_fit_after) - sum(introductions_by_first_sample_date_min, na.rm = T),
                  predicted_introductions_averted_max_fit_after = sum(predictions_max_fit_after) - sum(introductions_by_first_sample_date_min, na.rm = T))

prediced_introductions_averted_as_per <- introductions_vs_indicence_data %>% filter(date >= as.Date("2020-03-13"), date <= as.Date("2020-06-15")) %>%
        summarise(predicted_introductions_averted_max_asper =
                          (sum(predictions_max) - sum(introductions_by_first_sample_date_max, na.rm = T)) / sum(predictions_max),
                  predicted_introductions_averted_min_asper =
                          (sum(predictions_min) - sum(introductions_by_first_sample_date_min, na.rm = T)) / sum(predictions_min),
                  predicted_introductions_averted_min_fit_after_asper =
                          (sum(predictions_min_fit_after) - sum(introductions_by_first_sample_date_min, na.rm = T)) / sum(predictions_min_fit_after),
                  predicted_introductions_averted_max_fit_after_asper =
                          (sum(predictions_max_fit_after) - sum(introductions_by_first_sample_date_max, na.rm = T)) / sum(predictions_max_fit_after))

print(prediced_introductions_averted_as_per)

introsavertedmax <- unlist(prediced_introductions_averted$predicted_introductions_averted_max)
introsavertedmin <- unlist(prediced_introductions_averted$predicted_introductions_averted_min)

introsavertedaspermax <- unlist(prediced_introductions_averted_as_per$predicted_introductions_averted_max_asper)
introsavertedaspermin <- unlist(prediced_introductions_averted_as_per$predicted_introductions_averted_min_asper)

con <- file("manuscript/intoductions_by_incidence_model.tex", open = "w")
writeLines(text = paste0("\\newcommand\\casescoeffmax{", signif(cases_coeff_max, digits = 2), "}"), con = con)
writeLines(text = paste0("\\newcommand\\casescoeffmin{", signif(cases_coeff_min, digits = 2), "}"), con = con)
writeLines(text = paste0("\\newcommand\\casesdelaymax{", cases_delay_max, "}"), con = con)
writeLines(text = paste0("\\newcommand\\casesdelaymin{", cases_delay_min, "}"), con = con)
writeLines(text = paste0("\\newcommand\\introsavertedmax{", round(introsavertedmax, digits = 0), "}"), con = con)
writeLines(text = paste0("\\newcommand\\introsavertedmin{", round(introsavertedmin, digits = 0), "}"), con = con)
writeLines(text = paste0("\\newcommand\\introsavertedaspermax{", round(introsavertedaspermax * 100, digits = 0), "}"), con = con)
writeLines(text = paste0("\\newcommand\\introsavertedaspermin{", round(introsavertedaspermin * 100, digits = 0), "}"), con = con)
close(con)
```

Quantifying persistence around the lockdown: measure mean time to last sample for introductions spreading each day
```{r}
# Mean and Q1, Q3 lifespan of introductions spreading at each day in the sample period
is_first <- T
dates <- seq.Date(from = as.Date("2020-02-01"), to = as.Date("2020-12-01"), by = 1)
for (idx in seq_along(dates)) {
  start_date <- dates[idx]
  chains_on_date_data <- chain_summary_stats %>%
          filter(first_sample_date <= start_date, last_sample_date >= start_date) %>%
          mutate(days_continued_sampled = as.integer(last_sample_date - start_date)) %>%  # length of continued sampling after start_date
          select(chains_assumption, days_continued_sampled) %>%
          mutate(date = start_date)
  if (is_first) {
    persistence_results <- chains_on_date_data
    is_first <- F
  } else {
    persistence_results <- rbind(persistence_results, chains_on_date_data)
  }
}

# Smooth results
is_first <- T
dates <- seq.Date(from = as.Date("2020-02-01"), to = as.Date("2020-12-01"), by = 1)
window_size <- 0  # end inclusive, so estimates are based on time from x to last_sample_date distributions summed over date - 3 days <= x <= date + 3 days
for (idx in seq_along(dates)) {
  start_date <- dates[idx]
  smooth_results <- persistence_results %>%
          filter(date <= start_date + window_size, date >= start_date - window_size) %>%
          group_by(chains_assumption) %>%
          summarize(n = n(),
                    median = quantile(x = days_continued_sampled, probs = c(0.25, 0.5, 0.75))[2],
                    Q1 = quantile(x = days_continued_sampled, probs = c(0.25, 0.5, 0.75))[1],
                    Q3 = quantile(x = days_continued_sampled, probs = c(0.25, 0.5, 0.75))[3]) %>%
          mutate(date = start_date)
  if (is_first) {
    persistence_results_smooth <- smooth_results
    is_first <- F
  } else {
    persistence_results_smooth <- rbind(persistence_results_smooth, smooth_results)
  }
}

null_model <- persistence_results %>%
        filter(date <= as.Date("2020-07-01")) %>%
        group_by(chains_assumption) %>%
        summarise(median = quantile(x = days_continued_sampled, probs = c(0.25, 0.5, 0.75))[2],
                  Q1 = quantile(x = days_continued_sampled, probs = c(0.25, 0.5, 0.75))[1],
                  Q3 = quantile(x = days_continued_sampled, probs = c(0.25, 0.5, 0.75))[3])

persisence_over_time <- ggplot(data = persistence_results_smooth %>% filter(date <= as.Date("2020-07-01")), aes(x = date, fill = chains_assumption)) +
        geom_line(aes(y = median, color = chains_assumption)) +
        geom_ribbon(aes(ymin = Q1, ymax = Q3), alpha = 0.3) +
        scale_x_date(date_breaks = "1 week", date_labels = "%b. %d", limits = c(as.Date("2020-02-24"), as.Date("2020-07-01"))) +
        scale_fill_manual(labels = chain_assumption_labs, values = chains_assumption_colors, aesthetics = c("fill", "color"), name = element_blank()) +
        shared_theme +
        theme(axis.text.x = element_text(angle = 90, vjust = 0.5), legend.title = element_blank()) +
        scale_linetype_manual(values = c("Null model" = "dashed")) +
        labs(x = element_blank(), y = "\nPersistence (days)") +
        geom_rect(inherit.aes = F, data = highlight_data %>% filter(event == "Partial lockdown"),
                  aes(xmin = date_start, xmax = date_end, ymin = -Inf, ymax = Inf),
                  fill = "grey",
                  alpha = 0.3) +
        geom_hline(aes(yintercept = null_model$median[1], linetype = "Null model")) +
        geom_hline(aes(yintercept = null_model$median[2], linetype = "Null model")) # +
        # geom_hline(aes(yintercept = null_model$Q1[1], linetype = "Null model")) +
        # geom_hline(aes(yintercept = null_model$Q1[2], linetype = "Null model")) +
        # geom_hline(aes(yintercept = null_model$Q3[1], linetype = "Null model")) +
        # geom_hline(aes(yintercept = null_model$Q3[2], linetype = "Null model"))

persisence_over_time
```

Write out the persistence of introductions at the start of lockdown, post-lockdown peak
```{r}
lockdown_start_persistence <- persistence_results_smooth %>%
        filter(date == as.Date("2020-03-17"))
lockdown_end_persistence <- persistence_results_smooth %>%
        filter(date >= as.Date("2020-04-27")) %>%
        group_by(chains_assumption) %>%
        top_n(n = 1, wt = Q1)

con <- file("manuscript/persistence.tex", open = "w")
medpersistenceatlockdownmin <- unlist(lockdown_start_persistence[lockdown_start_persistence$chains_assumption == "min", "median"])
medpersistenceatlockdownmax <- unlist(lockdown_start_persistence[lockdown_start_persistence$chains_assumption == "max", "median"])
writeLines(text = paste0("\\newcommand\\medpersistenceatlockdownmin{", medpersistenceatlockdownmin, "}"), con = con)
writeLines(text = paste0("\\newcommand\\medpersistenceatlockdownmax{", medpersistenceatlockdownmax, "}"), con = con)

qonepersistenceatlockdownmin <- unlist(lockdown_start_persistence[lockdown_start_persistence$chains_assumption == "min", "Q1"])
qonepersistenceatlockdownmax <- unlist(lockdown_start_persistence[lockdown_start_persistence$chains_assumption == "max", "Q1"])
writeLines(text = paste0("\\newcommand\\qonepersistenceatlockdownmin{", qonepersistenceatlockdownmin, "}"), con = con)
writeLines(text = paste0("\\newcommand\\qonepersistenceatlockdownmax{", qonepersistenceatlockdownmax, "}"), con = con)

qthreepersistenceatlockdownmin <- unlist(lockdown_start_persistence[lockdown_start_persistence$chains_assumption == "min", "Q3"])
qthreepersistenceatlockdownmax <- unlist(lockdown_start_persistence[lockdown_start_persistence$chains_assumption == "max", "Q3"])
writeLines(text = paste0("\\newcommand\\qthreepersistenceatlockdownmin{", qthreepersistenceatlockdownmin, "}"), con = con)
writeLines(text = paste0("\\newcommand\\qthreepersistenceatlockdownmax{", qthreepersistenceatlockdownmax, "}"), con = con)

medpersistenceatpeakmin <- unlist(lockdown_end_persistence[lockdown_end_persistence$chains_assumption == "min", "median"])
medpersistenceatpeakmax <- unlist(lockdown_end_persistence[lockdown_end_persistence$chains_assumption == "max", "median"])
writeLines(text = paste0("\\newcommand\\medpersistenceatpeakmin{", medpersistenceatpeakmin, "}"), con = con)
writeLines(text = paste0("\\newcommand\\medpersistenceatpeakmax{", medpersistenceatpeakmax, "}"), con = con)

qonepersistenceatpeakmin <- unlist(lockdown_end_persistence[lockdown_end_persistence$chains_assumption == "min", "Q1"])
qonepersistenceatpeakmax <- unlist(lockdown_end_persistence[lockdown_end_persistence$chains_assumption == "max", "Q1"])
writeLines(text = paste0("\\newcommand\\qonepersistenceatpeakmin{", qonepersistenceatpeakmin, "}"), con = con)
writeLines(text = paste0("\\newcommand\\qonepersistenceatpeakmax{", qonepersistenceatpeakmax, "}"), con = con)

qthreepersistenceatpeakmin <- unlist(lockdown_end_persistence[lockdown_end_persistence$chains_assumption == "min", "Q3"])
qthreepersistenceatpeakmax <- unlist(lockdown_end_persistence[lockdown_end_persistence$chains_assumption == "max", "Q3"])
writeLines(text = paste0("\\newcommand\\qthreepersistenceatpeakmin{", qthreepersistenceatpeakmin, "}"), con = con)
writeLines(text = paste0("\\newcommand\\qthreepersistenceatpeakmax{", qthreepersistenceatpeakmax, "}"), con = con)
close(con)
```

Format comparative figure
```{r}
right_col <- plot_grid(introductions_vs_indicence_model, persisence_over_time,
          nrow = 2, align = "v", axis = "tb", labels = c("B", "D"))
left_col <- plot_grid(introductions_through_time, persistence_through_time,
                      nrow = 2, align = "v", axis = "tb", labels = c("A", "C"))

top_row <- plot_grid(left_col, right_col, nrow = 1, rel_widths = c(0.7, 1))

plot_grid(top_row, intervention_legend, nrow = 2, rel_heights = c(1, 0.1))

ggsave("figures/introductions_and_persistence_v2.png",
       width = double_col_width * 1.5, height = single_col_width, units = "cm")
```
